---
layout: post
date: 2018-02-11
title: flahsback 2008
categories: icfp 2008 programming
---
## Flashbak to ICFP2008 Contest

I was thinking back to when I last did the ICFP Programming contest, back in [2008](https://web.cecs.pdx.edu/~sheard/2008IcfpContest/) - when I did it in real-time, by myself. It was definitely hard work for 3 days.  

My entry was a bit of a mess - while I was planning to be all structured in my approach, when the clock struck 5AM on that Saturday, pretty much all planning went out the window and the coding started. At first it was ok, but the lack of a coherent architectural approach to solving the problem was definitely a hinderance the further I got into the contest (not that I got __that__ far).  I did work through most of the 3 days, and for a first, solo effort I did ok.  I got through the first round well under the max score cutoff, and only just missed out on getting through the second round by less than 1%.  I was team 'Soul Trader' - here are the results from [round 1](https://web.cecs.pdx.edu/~sheard/2008IcfpContest/results/final/results-by-score-Final-1.html) - yes I'm definitely in the bottom half - and from [round 2](https://web.cecs.pdx.edu/~sheard/2008IcfpContest/results/final/results-by-score-Final-2.html).  I don't know what the icons mean in the resluts table, but it doesn't look like my rover made it home on any of the trials - at least 2 timeouts and 1 crash... 

By that time, my code was so unmaintainable that all changes were super hard to make.  I knew I had to make a physics plugin and put in a PID or similar controller for steeing and acceleration, but aside from even just implementing those in code when you're 60+ hours into a competition with little sleep, the horrible structure of the application made it even more challenging.  Every change touched multiple parts of the code.

### Lessons learned

I did a little write-up for myself after the fact, and here are some of the take-outs I noted:

> A major failing of my v1.0 entry into the ICFP08 challenge was the lack of a decent support infrastucture, including:
> source control: I don't know how to use git/svn/cvs. Time to learn.
> code test environment: I tested by execution, not a unit test in sight
> deployment test environment: I had the LiveCD, but didn't use it
> post-mortem replay: I exclusively used the STDOUT traces to understand what happened when
> visualisation: the test servers were fine, but did not help that much with debugging, visualisation for post-mortems would have been good
> map builder: some teams built their own map builders that allows them to do some testing beyond the general maps provided.

There's more detailed handwringing on [blogger](http://team-soul-trader.blogspot.com.au/2008/07/icfp-2008-round-up-by-marcin-coles-team.html)

I'm trying to rectify this a little bit as I go through the ICFP2017 edition in slow time.  On reading some other notes I had at the time, it's obvious this came at my time of my interest in Rodney Brook's subsumption architecture for robotics.  I had some experience with it in writing C-code on MCUs for little robots, but most of that centred on self-preservation code (ie collision avoidance) rather than planning (eg path finding) and it was highly parallelised in the MCUs based on interrupts, but it seemed extensible. When I decided to do a second try in slow time (until my motivation gave way) and drew up an architecture for it.

![v2rover Subsumption architecture](/assets/v2r-architecture.png)

Unfortunately, I didn't get around to implementing it. Hopefully I'm a bit more committed this time :)
